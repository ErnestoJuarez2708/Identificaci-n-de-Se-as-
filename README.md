# ğŸ§  Proyecto de Reconocimiento de Lengua de SeÃ±as (ASL)

Este proyecto implementa un sistema de **reconocimiento de seÃ±as del alfabeto en ASL (American Sign Language)** mediante un modelo de visiÃ³n artificial en **Python** y una interfaz web desarrollada en **React + TypeScript + TailwindCSS**.

---

## ğŸ“ Estructura del Proyecto

ğŸ“‚ Proyecto-ASL/
â”‚
â”œâ”€â”€ frontend/
â”‚ â””â”€â”€ asl_agent/ # AplicaciÃ³n web (React + TS + Tailwind)
â”‚
â”œâ”€â”€ gold_dataset/ # Datos de referencia (para validaciÃ³n o ejemplos)
â”‚
â”œâ”€â”€ api.py # API principal (servidor Flask / FastAPI)
â”œâ”€â”€ agent.py # LÃ³gica del agente de predicciÃ³n
â”œâ”€â”€ tools.py # Utilidades del modelo
â”œâ”€â”€ asl_model.h5 # Modelo entrenado (Keras / TensorFlow)
â”‚
â”œâ”€â”€ pyproject.toml # ConfiguraciÃ³n del entorno uv
â”œâ”€â”€ uv.lock # Lockfile del entorno uv
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .python-version
â””â”€â”€ README.md

---

## âš™ï¸ Requisitos Previos

AsegÃºrate de tener instalados:

- **Python 3.10+**
- **uv** (gestor de entornos ultrarrÃ¡pido)  
  ğŸ‘‰ InstÃ¡lalo con:
  ```bash
  pip install uv
Node.js 18+

Git

Visual Studio Code (recomendado)

ğŸ ConfiguraciÃ³n del Backend (API)
Instalar dependencias con uv

Desde la raÃ­z del proyecto:

uv sync

Esto instalarÃ¡ automÃ¡ticamente todas las dependencias definidas en pyproject.toml.

Ejecutar la API

uv run python api.py

Si la API inicia correctamente, verÃ¡s algo como:

* Running on http://127.0.0.1:5000

âš ï¸ Deja esta terminal abierta, ya que el frontend se comunicarÃ¡ con este backend.

ğŸ’» ConfiguraciÃ³n del Frontend
Moverte al directorio del frontend

cd frontend/asl_agent

Instalar dependencias

npm install

Levantar el entorno de desarrollo

npm run dev
Esto iniciarÃ¡ el servidor local, normalmente en:

http://localhost:5173
Verificar conexiÃ³n con la API

En el archivo de configuraciÃ³n del frontend (por ejemplo .env o src/config.ts), asegÃºrate de tener la URL correcta:

VITE_API_URL=http://127.0.0.1:5000
ğŸ§  Flujo del Sistema

El frontend captura o carga una imagen de una seÃ±a.

EnvÃ­a la imagen a la API (api.py) mediante una peticiÃ³n HTTP.

La API usa el modelo (asl_model.h5) junto con utilidades en agent.py y tools.py para predecir la letra.

Devuelve un JSON con la predicciÃ³n, la confianza y el feedback generado:

json
Copiar cÃ³digo
{
  "pred_letter": "W",
  "confidence": 0.6975,
  "feedback": "AsegÃºrate de extender el dedo anular..."
}
El frontend muestra estos datos de manera visual y ordenada.
